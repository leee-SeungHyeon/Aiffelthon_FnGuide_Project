{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2d6e3c",
   "metadata": {},
   "source": [
    "# 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8ef8b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee6604c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1+cu111'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b678d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captum.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904c66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
    "from torch.nn import functional as F\n",
    "import re\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from konlpy.tag import Mecab\n",
    "import wandb\n",
    "import collections\n",
    "import pickle\n",
    "import kss\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from transformers import set_seed\n",
    "\n",
    "from ktextaug import TextAugmentation\n",
    "import ktextaug\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoModelForMaskedLM\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients, LayerActivation\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "import captum\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(random_seed)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28490692",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c9f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):#파일이름만 넣기\n",
    "    data_path = os.getenv('HOME') + '/aiffel/project/FnGuide/data/ad_news'#경로는 자신의 경로로 바꿔서 하면 됨\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    df = pd.read_csv(file_path, encoding='utf-8', delimiter='\\t')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325fa7b",
   "metadata": {},
   "source": [
    "## 사전학습 모델 및 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0a0e3",
   "metadata": {},
   "source": [
    "## kule/roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46613c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"klue/roberta-base\"  # 허깅페이스에서 모델만 갈아끼우면 됨\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, output_attentions=True)  # 예측하고자 하는 클래스의 수를 넣어줘야함\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 학습시킨 모델 불러오기\n",
    "model_save_folder = os.getenv('HOME') + \"/aiffel/project/FnGuide/model\"\n",
    "model_path = os.getenv('HOME') + \"/aiffel/project/FnGuide/model/klue_roberta-base_None_cross_entropy_stopword_classification_model_3.pt\" \n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71760d2f",
   "metadata": {},
   "source": [
    "## kfdeberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da48260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /aiffel/aiffel/project/FnGuide/kfdeberta-base and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name='kfdeberta-base'\n",
    "\n",
    "p_model_path = os.getenv('HOME') + \"/aiffel/project/FnGuide/kfdeberta-base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(p_model_path, num_labels=2, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(p_model_path)\n",
    "\n",
    "# 학습시킨 모델 불러오기\n",
    "model_save_folder = os.getenv('HOME') + \"/aiffel/project/FnGuide/model\"\n",
    "model_path = os.path.join(model_save_folder, \"kfdeberta-base_None_cross_entropy_stopword_classification_model_3.pt\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b29ad97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장 준비\n",
    "input_text = \"\"\"사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다.\"\"\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# 문장을 토큰화하여 인덱스로 변환하고, 토큰들을 리스트로 저장합니다.\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11cd1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 상태로 변경\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # base_model의 forward 함수를 호출하여 결과를 얻습니다.\n",
    "    # output_attentions=True로 설정하여 어텐션 가중치를 가져옵니다.\n",
    "    outputs = model(input_ids=input_ids, output_attentions=True)\n",
    "    \n",
    "    # 어텐션 가중치를 변수 attentions에 저장합니다.\n",
    "    attentions = outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6da3db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_token2token_scores(attentions: list, layer_idx: int):\n",
    "    \"\"\"\n",
    "    어텐션 가중치 시각화 함수\n",
    "    Input:\n",
    "        attentions (List[Tensor]): 레이어별 어텐션 가중치가 담긴 리스트\n",
    "        layer_idx (int): 시각화하고자 하는 레이어 인덱스\n",
    "\n",
    "    Returns:\n",
    "        None: 어텐션 가중치를 시각화하여 표시합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # layer_idx번째 레이어에 해당하는 어텐션 가중치의 shape를 확인하여 머리의 개수를 얻습니다.\n",
    "    num_heads = attentions[layer_idx].shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(num_heads, 1, figsize=(30, 90))\n",
    "\n",
    "    for head_idx in range(num_heads):\n",
    "        # layer_idx번째 레이어의 head_idx번째 머리의 어텐션 가중치를 가져옵니다.\n",
    "        scores_np = attentions[layer_idx][0, head_idx].detach().cpu().numpy()\n",
    "        \n",
    "        # subplot을 선택합니다. (만약 num_heads가 1이면 하나의 subplot만 사용합니다)\n",
    "        ax = axes[head_idx] if num_heads > 1 else axes\n",
    "        \n",
    "        # 어텐션 가중치를 이미지 형태로 그립니다.\n",
    "        im = ax.matshow(scores_np, cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(all_tokens)))\n",
    "        ax.set_yticks(range(len(all_tokens)))\n",
    "\n",
    "        ax.set_xticklabels(all_tokens, fontdict=fontdict, rotation=90)\n",
    "        ax.set_yticklabels(all_tokens, fontdict=fontdict)\n",
    "        ax.set_xlabel('Layer {}, Head {}'.format(layer_idx + 1, head_idx + 1))\n",
    "\n",
    "        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516cfda",
   "metadata": {},
   "source": [
    "### 원하는 레이어의 어텐션 맵 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ec860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# klue/roberta-base\n",
    "layer = 0\n",
    "visualize_token2token_scores(attentions, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac55aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kfdeberta-base\n",
    "layer = 0\n",
    "visualize_token2token_scores(attentions, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9813c0",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
